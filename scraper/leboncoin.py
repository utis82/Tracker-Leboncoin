from firecrawl import Firecrawl
import time
import os
from urllib.parse import quote_plus
from typing import List, Dict, Optional


class LeboncoinScraper:
    """Scraper pour les annonces Leboncoin via Firecrawl"""
    
    def __init__(self, api_key: Optional[str] = None):
        """
        Initialise le scraper Firecrawl
        
        Args:
            api_key: ClÃ© API Firecrawl (ou via variable d'environnement FIRECRAWL_API_KEY)
        """
        if api_key is None:
            api_key = os.getenv('FIRECRAWL_API_KEY', 'fc-779c2dbbb7264862a12028574a977e53')
        
        self.fc = Firecrawl(api_key=api_key)
        self.base_url = "https://www.leboncoin.fr/recherche"
        
    def build_url(self, model: str, year_min: int, year_max: int, page: int = 1) -> str:
        """
        Construit l'URL de recherche Leboncoin
        
        Args:
            model: ModÃ¨le de moto (ex: "triumph street triple 765 rs")
            year_min: AnnÃ©e minimum
            year_max: AnnÃ©e maximum
            page: NumÃ©ro de page
            
        Returns:
            URL complÃ¨te
        """
        params = {
            'category': '3',  # CatÃ©gorie motos
            'text': model.strip(),
            'regdate': f"{year_min}-{year_max}",
            'moto_type': 'moto'
        }
        
        # Construction manuelle de l'URL pour plus de contrÃ´le
        query_string = f"category={params['category']}"
        query_string += f"&text={quote_plus(params['text'])}"
        query_string += f"&regdate={params['regdate']}"
        query_string += f"&moto_type={params['moto_type']}"
        
        if page > 1:
            query_string += f"&page={page}"
        
        return f"{self.base_url}?{query_string}"
    
    def scrape_page(self, url: str) -> List[Dict]:
        """
        Scrape une page d'annonces
        
        Args:
            url: URL Ã  scraper
            
        Returns:
            Liste de dictionnaires contenant les donnÃ©es d'annonces
        """
        try:
            print(f"ğŸ“¡ Scraping: {url}")
            
            # Schema enrichi pour extraire plus de donnÃ©es
            schema = {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "title": {
                            "type": "string",
                            "description": "Le titre complet de l'annonce"
                        },
                        "price": {
                            "type": "string",
                            "description": "Le prix en euros (avec ou sans le symbole â‚¬)"
                        },
                        "mileage": {
                            "type": "string",
                            "description": "Le kilomÃ©trage (avec ou sans 'km')"
                        },
                        "year": {
                            "type": ["string", "integer"],
                            "description": "L'annÃ©e de mise en circulation"
                        },
                        "location": {
                            "type": "string",
                            "description": "La ville ou localisation"
                        },
                        "link": {
                            "type": "string",
                            "description": "Le lien complet vers l'annonce"
                        },
                        "photo": {
                            "type": "string",
                            "description": "L'URL de la premiÃ¨re photo de l'annonce"
                        }
                    },
                    "required": ["price", "mileage"]
                }
            }
            
            doc = self.fc.scrape(
                url,
                formats=[{
                    "type": "json",
                    "prompt": """Extract all motorcycle ads from this Leboncoin page.
                    For each ad, extract:
                    - title (full listing title)
                    - price (in euros)
                    - mileage (in km)
                    - year (registration year)
                    - location (city)
                    - link (full URL to the ad)
                    - photo (URL of the main image)
                    
                    Return an array of all ads found on the page.""",
                    "schema": schema
                }]
            )
            
            # Extraction des donnÃ©es
            if hasattr(doc, 'json') and doc.json:
                ads = doc.json if isinstance(doc.json, list) else [doc.json]
                print(f"âœ… {len(ads)} annonces extraites")
                return ads
            else:
                print("âš ï¸ Aucune donnÃ©e JSON retournÃ©e par Firecrawl")
                return []
                
        except Exception as e:
            print(f"âŒ Erreur lors du scraping: {str(e)}")
            return []
    
    def scrape(self, model: str, year_min: int, year_max: int, max_pages: int = 3) -> List[Dict]:
        """
        Scrape plusieurs pages d'annonces
        
        Args:
            model: ModÃ¨le de moto
            year_min: AnnÃ©e minimum
            year_max: AnnÃ©e maximum
            max_pages: Nombre maximum de pages Ã  scraper
            
        Returns:
            Liste complÃ¨te des annonces
        """
        all_ads = []
        
        print(f"\nğŸ” Recherche: {model} ({year_min}-{year_max})")
        print(f"ğŸ“„ Pages Ã  scanner: {max_pages}\n")
        
        for page in range(1, max_pages + 1):
            url = self.build_url(model, year_min, year_max, page)
            ads = self.scrape_page(url)
            
            if ads:
                all_ads.extend(ads)
                print(f"ğŸ“Š Total accumulÃ©: {len(all_ads)} annonces\n")
            else:
                print(f"âš ï¸ Page {page} vide ou erreur, arrÃªt du scraping\n")
                break
            
            # Pause entre les pages pour Ã©viter la surcharge
            if page < max_pages:
                time.sleep(1)
        
        print(f"âœ… Scraping terminÃ©: {len(all_ads)} annonces au total\n")
        return all_ads
    
    def scrape_with_retry(self, model: str, year_min: int, year_max: int, 
                          max_pages: int = 3, max_retries: int = 3) -> List[Dict]:
        """
        Scrape avec mÃ©canisme de retry en cas d'Ã©chec
        
        Args:
            model: ModÃ¨le de moto
            year_min: AnnÃ©e minimum
            year_max: AnnÃ©e maximum
            max_pages: Nombre maximum de pages
            max_retries: Nombre maximum de tentatives
            
        Returns:
            Liste des annonces
        """
        for attempt in range(1, max_retries + 1):
            try:
                ads = self.scrape(model, year_min, year_max, max_pages)
                if ads:
                    return ads
                
                if attempt < max_retries:
                    print(f"âš ï¸ Tentative {attempt}/{max_retries} Ã©chouÃ©e, nouvelle tentative dans 3s...")
                    time.sleep(3)
                    
            except Exception as e:
                print(f"âŒ Erreur tentative {attempt}/{max_retries}: {str(e)}")
                if attempt < max_retries:
                    time.sleep(3)
        
        print("âŒ Ã‰chec aprÃ¨s toutes les tentatives")
        return []


# Test du module
if __name__ == "__main__":
    scraper = LeboncoinScraper()
    
    # Test avec la Street Triple RS
    results = scraper.scrape(
        model="triumph street triple 765 rs",
        year_min=2017,
        year_max=2020,
        max_pages=2
    )
    
    print("\nğŸ“‹ RÃ©sumÃ© des rÃ©sultats:")
    print(f"Nombre d'annonces: {len(results)}")
    
    if results:
        print("\nğŸ” PremiÃ¨re annonce:")
        for key, value in results[0].items():
            print(f"  {key}: {value}")